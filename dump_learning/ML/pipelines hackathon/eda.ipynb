{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38247b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5adda436",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data\\\\train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6801883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ Kszta≈Çt danych: (0, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "      <th>data</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dummy, data, 1]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(f\"Kszta≈Çt danych: {df.shape}\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291380fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è Informacje o zbiorze danych:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 0 entries\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   dummy   0 non-null      object\n",
      " 1   data    0 non-null      object\n",
      " 2   1       0 non-null      object\n",
      "dtypes: object(3)\n",
      "memory usage: 132.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Informacje o zbiorze danych:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020bb6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Opis statystyczny danych numerycznych:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "      <th>data</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dummy data    1\n",
       "count      0    0    0\n",
       "unique     0    0    0\n",
       "top      NaN  NaN  NaN\n",
       "freq     NaN  NaN  NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Opis statystyczny danych numerycznych:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce1eb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß± Kolumny z brakami danych:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "missing = df.isna().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "print(\"Kolumny z brakami danych:\")\n",
    "display(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04debb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "num_cols = df.select_dtypes(include=[\"number\", \"bool\"]).columns.tolist()\n",
    "\n",
    "print(f\" Kolumny kategoryczne: {cat_cols}\")\n",
    "print(f\" Kolumny numeryczne: {num_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922958cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unikalne warto≈õci w zmiennych kategorycznych\n",
    "for col in cat_cols:\n",
    "    print(f\"{col}: {df[col].nunique()} unikalnych warto≈õci\")\n",
    "    print(df[col].value_counts(dropna=False).head())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7114e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sprawdzenie duplikat√≥w\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\" Liczba duplikat√≥w: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361d983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"target\"  \n",
    "if target_col in df.columns:\n",
    "    print(f\"Rozk≈Çad zmiennej docelowej: {target_col}\")\n",
    "    print(df[target_col].value_counts(normalize=True))\n",
    "    sns.countplot(x=df[target_col])\n",
    "    plt.title(\"Rozk≈Çad targetu\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64061df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxploty dla wykrywania outliers\n",
    "for col in num_cols:\n",
    "    if df[col].nunique() > 10:  # tylko dla sensownych zmiennych ciƒÖg≈Çych\n",
    "        plt.figure(figsize=(6, 1.5))\n",
    "        sns.boxplot(data=df, x=col)\n",
    "        plt.title(f\"Outliers in {col}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0b5205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#korelacje numeryczne\n",
    "corr = df[num_cols].corr()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True)\n",
    "plt.title(\" Korelacje miƒôdzy cechami numerycznymi\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230d15ed",
   "metadata": {},
   "source": [
    "## Pipeline - encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f1b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 1. Rozdzielenie kolumn\n",
    "cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "num_cols = df.select_dtypes(include=[\"number\", \"bool\"]).drop(columns=[target_col]).columns.tolist()\n",
    "\n",
    "print(f\" Kolumny kategoryczne: {cat_cols}\")\n",
    "print(f\" Kolumny numeryczne: {num_cols}\")\n",
    "\n",
    "# 2. Imputacja + kodowanie kategorii\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "# 3. Imputacja + skalowanie numer√≥w\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# 4. ColumnTransformer ‚Äì ≈ÇƒÖczy oba pipeline‚Äôy\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_cols),\n",
    "    (\"cat\", cat_pipeline, cat_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8c8bfd",
   "metadata": {},
   "source": [
    "## Encoding with column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c9f2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# ‚ú≥Ô∏è Lista kolumn kategorycznych\n",
    "cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "# üî† One-hot encoding\n",
    "encoder = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"), cat_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\"  # zachowaj kolumny numeryczne bez zmian\n",
    ")\n",
    "\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "print(\"Kszta≈Çt po kodowaniu:\", X_encoded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea85028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zak≈Çadamy, ≈ºe encoder zosta≈Ç dopasowany\n",
    "encoder = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"), cat_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\"  # zachowaj kolumny numeryczne bez zmian\n",
    ")\n",
    "ohe = encoder.named_transformers_[\"cat\"]\n",
    "encoded_feature_names = ohe.get_feature_names_out(cat_cols)\n",
    "\n",
    "# Inne kolumny (numeryczne) - nie zosta≈Çy zakodowane\n",
    "non_cat_cols = X.drop(columns=cat_cols).columns\n",
    "\n",
    "# Po≈ÇƒÖczenie nazw wszystkich cech\n",
    "all_feature_names = list(encoded_feature_names) + list(non_cat_cols)\n",
    "\n",
    "# Konwersja do DataFrame\n",
    "import pandas as pd\n",
    "X_encoded_df = pd.DataFrame(X_encoded, columns=all_feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058e5ad7",
   "metadata": {},
   "source": [
    "## Walidacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207e4b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "X_transformed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Je≈õli u≈ºywasz OneHotEncoder, dane bƒôdƒÖ jako NumPy array ‚Äî sprawd≈∫ shape\n",
    "print(\"Po przetworzeniu:\")\n",
    "print(\"X shape:\", X_transformed.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d043296c",
   "metadata": {},
   "source": [
    "### Train Model Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c3f0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# --- Klasyfikacja ---\n",
    "target_col = \"target\"  # <- zmie≈Ñ wed≈Çug danych\n",
    "\n",
    "# --- Dane ---\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# --- Podzia≈Ç danych ---\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# --- Rozdzielenie kolumn ---\n",
    "cat_cols = X_train.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "num_cols = X_train.select_dtypes(include=[\"number\", \"bool\"]).columns.tolist()\n",
    "\n",
    "# --- Imputacja brak√≥w ---\n",
    "X_train[cat_cols] = X_train[cat_cols].fillna(\"missing\")\n",
    "X_val[cat_cols] = X_val[cat_cols].fillna(\"missing\")\n",
    "\n",
    "for col in num_cols:\n",
    "    median = X_train[col].median()\n",
    "    X_train[col] = X_train[col].fillna(median)\n",
    "    X_val[col] = X_val[col].fillna(median)\n",
    "\n",
    "# --- Kodowanie kategorii ---\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "ohe.fit(X_train[cat_cols])\n",
    "\n",
    "X_train_cat = pd.DataFrame(ohe.transform(X_train[cat_cols]), columns=ohe.get_feature_names_out(cat_cols), index=X_train.index)\n",
    "X_val_cat = pd.DataFrame(ohe.transform(X_val[cat_cols]), columns=ohe.get_feature_names_out(cat_cols), index=X_val.index)\n",
    "\n",
    "# --- Skalowanie numeryczne ---\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[num_cols])\n",
    "\n",
    "X_train_num = pd.DataFrame(scaler.transform(X_train[num_cols]), columns=num_cols, index=X_train.index)\n",
    "X_val_num = pd.DataFrame(scaler.transform(X_val[num_cols]), columns=num_cols, index=X_val.index)\n",
    "\n",
    "# --- Finalne dane ---\n",
    "X_train_full = pd.concat([X_train_num, X_train_cat], axis=1)\n",
    "X_val_full = pd.concat([X_val_num, X_val_cat], axis=1)\n",
    "\n",
    "# --- Modele klasyfikacyjne ---\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(),\n",
    "    \"RandomForest\": RandomForestClassifier(),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "# --- Trening modeli ---\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n\\U0001F4C8 Trenowanie modelu: {name}\")\n",
    "    model.fit(X_train_full, y_train)\n",
    "    y_pred = model.predict(X_val_full)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "    print(f\"Accuracy: {acc:.4f} | F1-score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa57ff8",
   "metadata": {},
   "source": [
    "### Optuna Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360a559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# --- Dane ---\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "target_col = \"target\"  # <- zmie≈Ñ\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# --- Kolumny ---\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "num_cols = X.select_dtypes(include=[\"number\", \"bool\"]).columns.tolist()\n",
    "\n",
    "# --- Preprocessing ---\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_cols),\n",
    "    (\"cat\", cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "# --- Optuna objective ---\n",
    "def objective(trial):\n",
    "    model_name = trial.suggest_categorical(\"model\", [\n",
    "        \"logistic\", \"tree\", \"forest\", \"gboost\", \"xgb\"\n",
    "    ])\n",
    "\n",
    "    if model_name == \"logistic\":\n",
    "        model = LogisticRegression(\n",
    "            C=trial.suggest_float(\"lr_c\", 1e-3, 10.0, log=True),\n",
    "            max_iter=1000\n",
    "        )\n",
    "    elif model_name == \"tree\":\n",
    "        model = DecisionTreeClassifier(\n",
    "            max_depth=trial.suggest_int(\"tree_max_depth\", 2, 20),\n",
    "            min_samples_split=trial.suggest_int(\"tree_min_samples\", 2, 20)\n",
    "        )\n",
    "    elif model_name == \"forest\":\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=trial.suggest_int(\"rf_n\", 50, 300),\n",
    "            max_depth=trial.suggest_int(\"rf_max_depth\", 3, 20)\n",
    "        )\n",
    "    elif model_name == \"gboost\":\n",
    "        model = GradientBoostingClassifier(\n",
    "            n_estimators=trial.suggest_int(\"gb_n\", 50, 300),\n",
    "            learning_rate=trial.suggest_float(\"gb_lr\", 0.01, 0.3),\n",
    "            max_depth=trial.suggest_int(\"gb_max_depth\", 2, 10)\n",
    "        )\n",
    "    elif model_name == \"xgb\":\n",
    "        model = XGBClassifier(\n",
    "            use_label_encoder=False,\n",
    "            eval_metric=\"logloss\",\n",
    "            n_estimators=trial.suggest_int(\"xgb_n\", 50, 300),\n",
    "            learning_rate=trial.suggest_float(\"xgb_lr\", 0.01, 0.3),\n",
    "            max_depth=trial.suggest_int(\"xgb_max_depth\", 2, 10)\n",
    "        )\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    scores = cross_val_score(pipe, X_train, y_train, cv=3,\n",
    "                             scoring=make_scorer(f1_score, average=\"weighted\"))\n",
    "    return scores.mean()\n",
    "\n",
    "# --- Optuna run ---\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "print(\"\\n\\U0001F947 Najlepszy wynik:\")\n",
    "print(study.best_trial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68242543",
   "metadata": {},
   "source": [
    "### Clean optuna for hackathon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df324812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# X_train_full, y_train\n",
    "\n",
    "def objective(trial):\n",
    "    model_name = trial.suggest_categorical(\"model\", [\"logistic\", \"tree\", \"forest\", \"gboost\", \"xgb\"])\n",
    "\n",
    "    if model_name == \"logistic\":\n",
    "        model = LogisticRegression(\n",
    "            C=trial.suggest_float(\"lr_c\", 1e-3, 10.0, log=True),\n",
    "            max_iter=1000\n",
    "        )\n",
    "    elif model_name == \"tree\":\n",
    "        model = DecisionTreeClassifier(\n",
    "            max_depth=trial.suggest_int(\"tree_max_depth\", 2, 20),\n",
    "            min_samples_split=trial.suggest_int(\"tree_min_samples\", 2, 20)\n",
    "        )\n",
    "    elif model_name == \"forest\":\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=trial.suggest_int(\"rf_n\", 50, 300),\n",
    "            max_depth=trial.suggest_int(\"rf_max_depth\", 3, 20)\n",
    "        )\n",
    "    elif model_name == \"gboost\":\n",
    "        model = GradientBoostingClassifier(\n",
    "            n_estimators=trial.suggest_int(\"gb_n\", 50, 300),\n",
    "            learning_rate=trial.suggest_float(\"gb_lr\", 0.01, 0.3),\n",
    "            max_depth=trial.suggest_int(\"gb_max_depth\", 2, 10)\n",
    "        )\n",
    "    elif model_name == \"xgb\":\n",
    "        model = XGBClassifier(\n",
    "            use_label_encoder=False,\n",
    "            eval_metric=\"logloss\",\n",
    "            n_estimators=trial.suggest_int(\"xgb_n\", 50, 300),\n",
    "            learning_rate=trial.suggest_float(\"xgb_lr\", 0.01, 0.3),\n",
    "            max_depth=trial.suggest_int(\"xgb_max_depth\", 2, 10)\n",
    "        )\n",
    "\n",
    "    # Walidacja krzy≈ºowa\n",
    "    score = cross_val_score(\n",
    "        model,\n",
    "        X_train_full,\n",
    "        y_train,\n",
    "        cv=3,\n",
    "        scoring=make_scorer(f1_score, average=\"weighted\")\n",
    "    ).mean()\n",
    "\n",
    "    return score\n",
    "\n",
    "# Uruchomienie Optuny\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "print(\"üèÜ Najlepszy wynik:\")\n",
    "print(study.best_trial)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
