{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pochodna f(x): 3*x**2 + 4*x - 5\n"
     ]
    }
   ],
   "source": [
    "import sympy as sp\n",
    "\n",
    "# Definiujemy zmienną x i funkcję f(x)\n",
    "x = sp.Symbol('x')\n",
    "f = x**3 + 2*x**2 - 5*x + 7\n",
    "\n",
    "# Obliczamy pochodną\n",
    "f_prime = sp.diff(f, x)\n",
    "print(\"Pochodna f(x):\", f_prime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pochodna w x=2: 15\n"
     ]
    }
   ],
   "source": [
    "# Obliczamy pochodną w x=2\n",
    "f_prime_value = f_prime.subs(x, 2)\n",
    "print(\"Pochodna w x=2:\", f_prime_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pochodna po x: 2*x + 3*y\n",
      "Pochodna po y: 3*x + 2*y\n"
     ]
    }
   ],
   "source": [
    "# Definiujemy zmienne x, y i funkcję g(x, y)\n",
    "y = sp.Symbol('y')\n",
    "g = x**2 + 3*x*y + y**2\n",
    "\n",
    "# Pochodne cząstkowe\n",
    "g_dx = sp.diff(g, x)  # Pochodna po x\n",
    "g_dy = sp.diff(g, y)  # Pochodna po y\n",
    "\n",
    "print(\"Pochodna po x:\", g_dx)\n",
    "print(\"Pochodna po y:\", g_dy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient:\n",
      " Matrix([[2*x + 3*y], [3*x + 2*y]])\n"
     ]
    }
   ],
   "source": [
    "# Gradient funkcji g(x, y)\n",
    "gradient = sp.Matrix([g_dx, g_dy])\n",
    "print(\"Gradient:\\n\", gradient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracja 1: w = -0.7633, J(w) = 0.2927\n",
      "Iteracja 2: w = -0.9107, J(w) = 0.0973\n",
      "Iteracja 3: w = -1.0285, J(w) = -0.0277\n",
      "Iteracja 4: w = -1.1228, J(w) = -0.1077\n",
      "Iteracja 5: w = -1.1983, J(w) = -0.1590\n",
      "Iteracja 6: w = -1.2586, J(w) = -0.1917\n",
      "Iteracja 7: w = -1.3069, J(w) = -0.2127\n",
      "Iteracja 8: w = -1.3455, J(w) = -0.2261\n",
      "Iteracja 9: w = -1.3764, J(w) = -0.2347\n",
      "Iteracja 10: w = -1.4011, J(w) = -0.2402\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Funkcja kosztu J(w) = w^2 + 3w + 2\n",
    "def cost_function(w):\n",
    "    return w**2 + 3*w + 2\n",
    "\n",
    "# Pochodna funkcji kosztu\n",
    "def cost_derivative(w):\n",
    "    return 2*w + 3\n",
    "\n",
    "# Gradient Descent\n",
    "def gradient_descent(learning_rate=0.1, epochs=10):\n",
    "    w = np.random.randn()  # Inicjalizacja losowego w\n",
    "    for i in range(epochs):\n",
    "        grad = cost_derivative(w)\n",
    "        w -= learning_rate * grad  # Aktualizacja wag\n",
    "        print(f\"Iteracja {i+1}: w = {w:.4f}, J(w) = {cost_function(w):.4f}\")\n",
    "\n",
    "gradient_descent()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
